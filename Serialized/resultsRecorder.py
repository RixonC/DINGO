# -*- coding: utf-8 -*-

from __future__ import division

import os
import time
import matplotlib
matplotlib.use('agg')
import matplotlib.pyplot as plt
import numpy as np
import torch
from worker import Worker


class ResultsRecorder(object):
    '''This class loads, saves and plots results.

    Args:
        algorithm: The algorithm being used.
        config: A dictionary of all necessary parameters.
        test_X: test features.
        test_Y: test labels.
    '''
    def __init__(self, algorithm, config, test_X=None, test_Y=None):
        self.algorithm = algorithm
        self.config = config
        self.test_X = test_X
        self.test_Y = test_Y
        if test_X is not None:
            self.worker = Worker(test_X, test_Y, config)


    ################################################################################################
    #----------------------------------- Save and Retrieve Runs -----------------------------------#

    def get_save_keys(self):
        '''Return a list of all parameters relevant to the current algorithm.'''
        keys = ['num_partitions','max_iterations','max_communication_rounds','grad_tol','lamda','obj_fun','dataset','dataset_train_X_size','dataset_train_Y_size','w0_str']
        if self.algorithm not in ['Synchronous SGD', 'Asynchronous SGD']:
            keys += ['subproblem_max_iterations','subproblem_tolerance','use_preconditioning_in_subproblem']
        if self.algorithm in ['GIANT', 'DINGO']:
            keys += ['line_search_max_iterations','line_search_rho','line_search_start_val']
        if self.algorithm == 'DINGO':
            keys += ['DINGO_theta', 'DINGO_phi']
        if self.algorithm == 'DISCO':
            keys += ['DISCO_mu']
        if self.algorithm in ['InexactDANE', 'AIDE']:
            keys += ['inexactDANE_SVRG_stepsize', 'inexactDANE_eta', 'inexactDANE_mu']
        if self.algorithm == 'AIDE':
            keys += ['AIDE_tau']
        if self.algorithm == 'Synchronous SGD':
            keys += ['Synchronous_SGD_stepsize']
        if self.algorithm == 'Asynchronous SGD':
            keys += ['Asynchronous_SGD_stepsize']
        if self.algorithm in ['Synchronous SGD', 'Asynchronous SGD']:
            keys += ['SGD_minibatch_size']
        if self.config['obj_fun'] == 'Autoencoder':
            keys += ['autoencoder_layers']
        return keys


    def prepair_save_data(self):
        '''Return the file name and dictionary to be saved under.'''
        save_dictionary = {}
        keys = self.get_save_keys()
        for k in keys:
            save_dictionary[k] = self.config[k]
        save_name = './Plots/PlotData/{}/{}{}_{}_{}_{}'.format(self.config['obj_fun'],self.config['dataset'],self.config['num_partitions'],self.algorithm,self.config['obj_fun'],time.strftime("%Y-%m-%d %H-%M-%S", time.gmtime()))
        return save_name, save_dictionary


    def save_plots_data(self, weights, end_message, lists):
        '''Save the results of the experiment.

        Args:
            weights: The final point.
            end_message: Why the algorithm stopped.
            lists: The dictionary containing the lists of results.
        '''
        save_name, save_dictionary = self.prepair_save_data()
        save_dictionary['final_weights'] = weights
        save_dictionary['end_message'] = end_message
        save_dictionary['lists'] = lists
        np.save(save_name, save_dictionary)


    def get_plot_data(self):
        '''Find and return the results of an experiment matching the current experiment configuration.'''
        save_name, current_dictionary = self.prepair_save_data()
        for file in os.listdir('./Plots/PlotData/{}/'.format(self.config['obj_fun'])):
            splitFile = file.split('_')
            if (splitFile[0] == self.config['dataset'] + str(self.config['num_partitions'])) and (splitFile[1] == self.algorithm) and (splitFile[2] == self.config['obj_fun']):
                fileDictionary =  np.load('./Plots/PlotData/{}/{}'.format(self.config['obj_fun'], file)).flat[0]
                if all([current_dictionary.get(key) == fileDictionary.get(key) for key in self.get_save_keys()]):
                    return fileDictionary['final_weights'], fileDictionary['end_message'], fileDictionary['lists']
        return None


    ################################################################################################
    #--------------------------------------- Plot results -----------------------------------------#

    def print_sample(self, w):
        '''Print an image generated by the Autoencoder.

        Args:
            w: The weights of the Autoencoder.
        '''
        if self.config['obj_fun'] != 'Autoencoder':
            return None
        elif self.config['dataset'] not in ['MNIST', 'Fashion_MNIST', 'CIFAR10', 'SVHN', 'Curves']:
            return None
        else:
            sample_X = self.test_X[2:3]
            sample_Y = self.test_Y[2:3]
            W = Worker(sample_X, sample_Y, self.config)

            autoencoder_w0 = W.autoencoder(self.config['w0'])
            autoencoder_w = W.autoencoder(w)

            img_original = sample_X
            img_w0 = autoencoder_w0(sample_X)
            img_w  = autoencoder_w(sample_X)

        if self.config['dataset'] in ['MNIST', 'Fashion_MNIST', 'Curves']:
            img_original = img_original.reshape(28,28).cpu().numpy()
            img_w0 = img_w0.reshape(28,28).detach().cpu().numpy()
            img_w = img_w.reshape(28,28).detach().cpu().numpy()

        if self.config['dataset'] in ['CIFAR10', 'SVHN']:
            img_original = img_original.reshape(3,32,32).cpu().numpy()
            img_original = np.transpose(img_original, (1, 2, 0))

            img_w0 = img_w0.reshape(3,32,32).detach().cpu().numpy()
            img_w0 = np.transpose(img_w0, (1, 2, 0))
            img_w0 = 256*(img_w0-img_w0.min())/(img_w0.max()-img_w0.min()) # elements are now in range 0 to 255
            img_w0 = img_w0.astype('uint8')

            img_w = img_w.reshape(3,32,32).detach().cpu().numpy()
            img_w = np.transpose(img_w, (1, 2, 0))
            img_w = 256*(img_w-img_w.min())/(img_w.max()-img_w.min())
            img_w = img_w.astype('uint8')

        num_plots = len(self.config['algorithms']) + 2
        rc = 100 + 10*num_plots

        plt.figure(2, figsize=(num_plots*4, 4))
        plt.suptitle('m = ' + str(self.config['num_partitions']))
        if self.algorithm == self.config['algorithms'][0]:
            plt.subplot(rc+1)
            plt.title('Input')
            plt.imshow(img_original, cmap='gray')
            plt.subplot(rc+2)
            plt.title(r'Initial Weights $\mathbf{w}_0$')
            plt.imshow(img_w0, cmap='gray')
        plt.subplot(rc+self.config['algorithms'].index(self.algorithm)+3)
        plt.title(self.algorithm)
        plt.imshow(img_w, cmap='gray')
        plt.savefig('./Plots/' + self.config['dataset'] + str(self.config['num_partitions']), dpi=200, bbox_inches='tight')


    def record_accuracy(self, w):
        '''Return the test accuracy or error.

        Args:
            w: The current point.
        '''
        if self.test_X is not None:
            if self.config['obj_fun'] == 'softmax':
                n,d = self.test_X.shape
                C = int(len(w)/d)
                W = w.reshape(C, d).transpose(0,1) # [d,C]
                XW = torch.mm(self.test_X, W) # [n,C]
                large_vals = torch.max(XW, dim=1, keepdim=True)[0] # [n,1]
                large_vals = torch.max(large_vals, torch.Tensor([float(0)])) #M(x), [n,1]
                #XW - M(x)/<Xi,Wc> - M(x), [n x C]
                XW_trick = XW - large_vals.repeat(1, C) # [n,C]
                #sum over b to calc alphax, [n x total_C]
                XW_1_trick = torch.cat((-large_vals, XW_trick), dim=1) # [n,C+1]
                #alphax, [n, ]
                sum_exp_trick = torch.exp(XW_1_trick).sum(dim=1, keepdim=True) # [n,1]
                inv_sum_exp = 1./sum_exp_trick # [n,1]
                inv_sum_exp = inv_sum_exp.repeat(1, C) # [n,C]
                probability = torch.mul(inv_sum_exp, torch.exp(XW_trick)) # [n,C]
                probability = torch.cat((probability, 1-probability.sum(dim=1, keepdim=True)), dim=1) # [n,C+1]
                predicted_labels = torch.max(probability, dim=1, keepdim=False)[1]
                actual_labels = torch.max(self.test_Y, dim=1, keepdim=False)[1]
                accuracy = 100*torch.sum(actual_labels == predicted_labels)/n
                return accuracy
            else:
                return self.worker.loss(w)
        else:
            return None


    def print_row(self, iteration, lists, final_row=False):
        '''Print the row of the results table corresponding to the iteration.

        Args:
            iteration: The current iteration.
            lists: The dictionary of lists containing the algorithm results.
            final_row: A boolean indicating if this is the last row of the results table.
        '''
        if self.algorithm == 'GIANT':
            header = '     Iter    CCR   AvgIterSolver    ||p||       Angle     IterLS     Alpha     Time      f        ||g||'
        if self.algorithm == 'DINGO':
            header = '     Iter    CCR   Case   AvgLagrLambda    ||p||       Angle     IterLS     Alpha     Time      f        ||g||'
        if self.algorithm == 'DISCO':
            header = '     Iter    CCR   PCG_iters   Delta     Time      f        ||g||'
        if self.algorithm == 'InexactDANE':
            header = '     Iter    CCR   Time      f        ||g||'
        if self.algorithm == 'AIDE':
            header = '     Iter    CCR   Time      f        ||g||'
        if self.algorithm in ['Synchronous SGD', 'Asynchronous SGD']:
            header = '     Iter    CCR    ||p||     Time      f        ||g||'
        if self.test_X is not None:
            header += '      Test'
        
        if self.algorithm == 'GIANT':
            if (iteration) % 20 == 0: # Print the header every 20 iterations
                print(header)
            if final_row:
                f    = lists.get('loss_list')[-1]
                g    = lists.get('grad_norm_list')[-1]
                prt  = '%8g%86.2e%11.2e' % (iteration,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[-1]
                    prt += '%11.2e' % (test)
                print(prt)
            else:
                k      = iteration
                c      = lists.get('cumulative_communication_rounds_list')[k]
                ais    = lists.get('iter_solver_list')[k]
                p      = lists.get('direction_norm_list')[k]
                ip     = lists.get('inner_prod_list')[k]
                iterLS = lists.get('ls_iters_list')[k]
                alpha  = lists.get('alpha_list')[k]
                t      = lists.get('time_list')[k]
                f      = lists.get('loss_list')[k]
                g      = lists.get('grad_norm_list')[k]
                
                prt3 = '%7.2f%11.2e%11.2e' % (t,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[k]
                    prt3 += '%11.2e' % (test)

                prt1 = '%8g%8g%12.2f%15.2e%12.2e' % (k,c,ais,p,ip)
                prt2 = '%7g%14.2e' % (iterLS, alpha)
                print(prt1 + prt2 + prt3)

        if self.algorithm == 'DINGO':
            if (iteration) % 20 == 0: # Print the header every 20 iterations
                print(header)
            if final_row:
                f    = lists.get('loss_list')[-1]
                g    = lists.get('grad_norm_list')[-1]
                prt  = '%8g%93.2e%11.2e' % (iteration,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[-1]
                    prt += '%11.2e' % (test)
                print(prt)
            else:
                k      = iteration
                c      = lists.get('cumulative_communication_rounds_list')[k]
                case   = lists.get('cases_list')[k]
                ais    = lists.get('avg_Lagrangian_lambda_list')[k]
                p      = lists.get('direction_norm_list')[k]
                ip     = lists.get('inner_prod_list')[k]
                iterLS = lists.get('ls_iters_list')[k]
                alpha  = lists.get('alpha_list')[k]
                t      = lists.get('time_list')[k]
                f      = lists.get('loss_list')[k]
                g      = lists.get('grad_norm_list')[k]
                
                prt3 = '%8.2f%11.2e%11.2e' % (t,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[k]
                    prt3 += '%11.2e' % (test)

                prt1 = '%8g%8g%7g%14.2e%13.2e%12.2e' % (k,c,case,ais,p,ip)
                prt2 = '%6g%14.2e' % (iterLS, alpha)
                print(prt1 + prt2 + prt3)

        if self.algorithm == 'DISCO':
            if (iteration) % 20 == 0: # Print the header every 20 iterations
                print(header)
            if final_row:
                f    = lists.get('loss_list')[-1]
                g    = lists.get('grad_norm_list')[-1]
                prt  = '%8g%48.2e%11.2e' % (iteration,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[-1]
                    prt += '%11.2e' % (test)
                print(prt)
            else:
                k      = iteration
                c      = lists.get('cumulative_communication_rounds_list')[k]
                PCG    = lists.get('PCG_iters_list')[k]
                delta  = lists.get('delta_list')[k]
                t      = lists.get('time_list')[k]
                f      = lists.get('loss_list')[k]
                g      = lists.get('grad_norm_list')[k]
                
                prt2 = '%7.2f%11.2e%11.2e' % (t,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[k]
                    prt2 += '%11.2e' % (test)

                prt1 = '%8g%8g%10.2f%12.2e' % (k,c,PCG,delta)
                print(prt1 + prt2)

        if self.algorithm == 'InexactDANE':
            if (iteration) % 20 == 0: # Print the header every 20 iterations
                print(header)
            if final_row:
                f    = lists.get('loss_list')[-1]
                g    = lists.get('grad_norm_list')[-1]
                prt  = '%8g%26.2e%11.2e' % (iteration,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[-1]
                    prt += '%11.2e' % (test)
                print(prt)
            else:
                k    = iteration
                c    = lists.get('cumulative_communication_rounds_list')[k]
                t    = lists.get('time_list')[k]
                f    = lists.get('loss_list')[k]
                g    = lists.get('grad_norm_list')[k]
                
                prt2 = '%7.2f%11.2e%11.2e' % (t,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[k]
                    prt2 += '%11.2e' % (test)

                prt1 = '%8g%8g' % (k,c)
                print(prt1 + prt2)

        if self.algorithm == 'AIDE':
            if (iteration) % 20 == 0: # Print the header every 20 iterations
                print(header)
            if final_row:
                f    = lists.get('loss_list')[-1]
                g    = lists.get('grad_norm_list')[-1]
                prt  = '%8g%26.2e%11.2e' % (iteration,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[-1]
                    prt += '%11.2e' % (test)
                print(prt)
            else:
                k    = iteration
                c    = lists.get('cumulative_communication_rounds_list')[k]
                t    = lists.get('time_list')[k]
                f    = lists.get('loss_list')[k]
                g    = lists.get('grad_norm_list')[k]
                
                prt2 = '%7.2f%11.2e%11.2e' % (t,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[k]
                    prt2 += '%11.2e' % (test)

                prt1 = '%8g%8g' % (k,c)
                print(prt1 + prt2)

        if self.algorithm in ['Synchronous SGD', 'Asynchronous SGD']:
            if (iteration) % 20 == 0: # Print the header every 20 iterations
                print(header)
            if final_row:
                f    = lists.get('loss_list')[-1]
                g    = lists.get('grad_norm_list')[-1]
                prt  = '%8g%37.2e%11.2e' % (iteration,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[-1]
                    prt += '%11.2e' % (test)
                print(prt)
            else:
                k    = iteration
                c    = lists.get('cumulative_communication_rounds_list')[k]
                p    = lists.get('direction_norm_list')[k]
                t    = lists.get('time_list')[k]
                f    = lists.get('loss_list')[k]
                g    = lists.get('grad_norm_list')[k]
                
                prt2 = '%7.2f%11.2e%11.2e' % (t,f,g)
                if self.test_X is not None:
                    test = lists.get('test_accuracy_list')[k]
                    prt2 += '%11.2e' % (test)

                prt1 = '%8g%8g%11.2e' % (k,c,p)
                print(prt1 + prt2)


    def print_plots(self, end_message, lists, subproblem_failed_end_message=None):
        '''Print the results plots.

        Args:
            end_message: Why the algorithm stopped.
            lists: The dictionary of lists containing the algorithm results.
            subproblem_failed_end_message: Why the sub-problem solver failed, if it did.
        '''
        label = self.algorithm

        if self.algorithm == 'GIANT':
            colour = 'g'
            style = '-.'
        if self.algorithm == 'DINGO':
            colour = 'k'
            if self.config['DINGO_theta'] == 1e+0:
                style = '-.'
            elif self.config['DINGO_theta'] == 1e+2:
                style = ':'
            else:
                style = '-'
        if self.algorithm == 'DISCO':
            colour = 'c'
            style = '-.'
        if self.algorithm == 'InexactDANE':
            colour = 'm'
            style = ':'
        if self.algorithm == 'AIDE':
            colour = 'r'
            style = ':'
        if self.algorithm == 'Asynchronous SGD':
            colour = 'y'
            style = '--'
        if self.algorithm == 'Synchronous SGD':
            colour = 'b'
            style = '--'

        print_alphas = ('GIANT' in self.config['algorithms']) or ('DINGO' in self.config['algorithms'])

        if (self.test_X is not None) and print_alphas:
            size=(4, 16)
            rc = 410
        elif (self.test_X is not None):
            size=(4, 12)
            rc = 310
        elif print_alphas:
            size=(4, 12)
            rc = 310
        else:
            size=(4, 8)
            rc = 210

        cumulative_communication_rounds_list = [0] + lists['cumulative_communication_rounds_list']

        plt.figure(1, figsize=size)
        plt.subplots_adjust(hspace = 0.3)

        plt.subplot(rc+1)
        plt.plot(cumulative_communication_rounds_list,
                 lists['loss_list'],
                 color=colour,
                 linestyle=style,
                 label=label)
        if end_message == subproblem_failed_end_message:
            plt.plot(cumulative_communication_rounds_list[-1:],
                     lists['loss_list'][-1:],
                     color=colour,
                     linestyle=style,
                     marker='x')
        plt.xlabel('Communication Rounds')
        plt.ylabel(r'Objective Function: $f\:(\mathbf{w})$')
        if cumulative_communication_rounds_list[-1] > self.config['max_communication_rounds']:
            plt.xlim(xmax=self.config['max_communication_rounds'])

        plt.subplot(rc+2)
        plt.semilogy(cumulative_communication_rounds_list,
                     lists['grad_norm_list'],
                     color=colour,
                     linestyle=style,
                     label=label)
        if end_message == subproblem_failed_end_message:
            plt.semilogy(cumulative_communication_rounds_list[-1:],
                         lists['grad_norm_list'][-1:],
                         color=colour,
                         linestyle=style,
                         marker='x')
        plt.xlabel('Communication Rounds')
        plt.ylabel(r'Gradient Norm: $||\nabla f(\mathbf{w})||$')
        if cumulative_communication_rounds_list[-1] > self.config['max_communication_rounds']:
            plt.xlim(xmax=self.config['max_communication_rounds'])

        if self.algorithm in ['GIANT','DINGO']:
            plt.subplot(rc+3)
            plt.semilogy(lists['alpha_list'],
                         color=colour,
                         linestyle=style,
                         label=label)
            if end_message == subproblem_failed_end_message and len(lists['alpha_list'])>0:
                plt.semilogy(len(lists['alpha_list']),
                             lists['alpha_list'][-1],
                             color=colour,
                             linestyle=style,
                             marker='x')
            plt.xlabel('Iteration')
            plt.ylabel(r'Line Search: $\alpha$')

        if self.test_X is not None:
            if print_alphas:
                plt.subplot(rc+4)
            else:
                plt.subplot(rc+3)
            if self.config['obj_fun'] == 'softmax':
                plt.plot(cumulative_communication_rounds_list,
                         lists['test_accuracy_list'],
                         color=colour,
                         linestyle=style,
                         label=label)
                if end_message == subproblem_failed_end_message:
                    plt.plot(cumulative_communication_rounds_list[-1:],
                             lists['test_accuracy_list'][-1:],
                             color=colour,
                             linestyle=style,
                             marker='x')
                plt.xlabel('Communication Rounds')
                plt.ylabel('Test Classification Accuracy (%)')
                if cumulative_communication_rounds_list[-1] > self.config['max_communication_rounds']:
                    plt.xlim(xmax=self.config['max_communication_rounds'])
            else:
                plt.plot(cumulative_communication_rounds_list,
                         lists['test_accuracy_list'],
                         color=colour,
                         linestyle=style,
                         label=label)
                if end_message == subproblem_failed_end_message:
                    plt.plot(cumulative_communication_rounds_list[-1:],
                             lists['test_accuracy_list'][-1:],
                             color=colour,
                             linestyle=style,
                             marker='x')
                plt.xlabel('Communication Rounds')
                plt.ylabel('Test Error')
                if cumulative_communication_rounds_list[-1] > self.config['max_communication_rounds']:
                    plt.xlim(xmax=self.config['max_communication_rounds'])

        plt.savefig('./Plots/' + str(self.config['obj_fun']) + '_' + self.config['dataset'] + '_' + str(self.config['num_partitions']) + '.pdf', bbox_inches='tight')
